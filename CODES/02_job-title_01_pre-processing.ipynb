{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to work with dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to preprocess text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "# from collections import Counter\n",
    "\n",
    "# Libraries to visualize data\n",
    "from tqdm import tqdm     # displaying progress bar while running computation\n",
    "\n",
    "# Download neccessary resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurate and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"E:/THIENDHB_GOOGLEDRIVE/MASTER TILBURG/THESIS/\"\n",
    "INPUT_DIR = BASE_DIR + \"DATASET/INPUT/\"\n",
    "OUTPUT_DIR = BASE_DIR + \"DATASET/OUTPUT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.read_csv(INPUT_DIR + \"refined_jobpost_data.csv\", usecols=[\"job_title\"])\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18992, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Financial Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full-time Community Connections Intern (paid internship)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Country Coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BCC Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saleswoman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chief Accountant/ Finance Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-paid part or full time Programmatic Intern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assistant to Managing Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Program Assistant (INL), FSN-8; FP-6*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  job_title\n",
       "0                                   Chief Financial Officer\n",
       "1  Full-time Community Connections Intern (paid internship)\n",
       "2                                       Country Coordinator\n",
       "3                                            BCC Specialist\n",
       "4                                        Software Developer\n",
       "5                                                Saleswoman\n",
       "6                       Chief Accountant/ Finance Assistant\n",
       "7            Non-paid part or full time Programmatic Intern\n",
       "8                            Assistant to Managing Director\n",
       "9                     Program Assistant (INL), FSN-8; FP-6*"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job_title'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    \"\"\"Helper function to convert nltk POS tags to wordnet POS tags\"\"\"\n",
    "    if nltk_tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def lemmatize_token(token):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nltk_tagged = nltk.pos_tag(token)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # if no tag found then use as it is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            # else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "\n",
    "class pre_process_text:\n",
    "    \"\"\"Function to pre process text once for all steps:\n",
    "    - Removing URLs\n",
    "    - Removing stop words\n",
    "    - Removing special characters and numbers\n",
    "    - Removing rare words (frequency = 1)\n",
    "    - Lowercasing\n",
    "    - Lemmatizing\n",
    "\n",
    "    Inputs:\n",
    "    - text: raw text to normalize\n",
    "    - spec_chars: list of special characters to remove\n",
    "    - stop_words: set of stopwords to remove\n",
    "\n",
    "    Return: normalized text\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, spec_chars, stop_words):\n",
    "        self.text = text\n",
    "        self.spec_chars = spec_chars\n",
    "        self.stop_words = stop_words\n",
    "\n",
    "    def convert2string(self):\n",
    "        self.text = str(self.text)\n",
    "        return self\n",
    "\n",
    "    def lowercase(self):\n",
    "        # convert to string and lowercasing\n",
    "        self.text = self.text.lower()\n",
    "        return self\n",
    "\n",
    "    def remove_url(self):\n",
    "        # remove URLs\n",
    "        self.text = re.sub(r\"http\\S+\", \"\", self.text)\n",
    "        self.text = re.sub(r\"www\\S+\", \"\", self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_spec_chars(self):\n",
    "        # remove special characters and numbers\n",
    "        # self.text = self.text.translate(str.maketrans(\"\", \"\", self.spec_chars))\n",
    "        for char in self.spec_chars:\n",
    "            self.text = self.text.replace(char, \" \")\n",
    "        self.text = re.sub(\"[ ]{2,}\", \" \", self.text)\n",
    "        return self\n",
    "\n",
    "    def replace_spec_chars(self):\n",
    "        # replace special characters and numbers with |\n",
    "        for char in self.spec_chars:\n",
    "            self.text = self.text.replace(char, \"|\")\n",
    "        self.text = re.sub(\"[|]{2,}\", \"|\", self.text)\n",
    "        return self\n",
    "\n",
    "    def get_tokens(self):\n",
    "        # tokenize\n",
    "        self.text = nltk.word_tokenize(self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_stopwords(self):\n",
    "        # remove stop words\n",
    "        self.text = [word for word in self.text if word not in self.stop_words]\n",
    "        return self\n",
    "\n",
    "    def lemmatize(self):\n",
    "        # lemmatize\n",
    "        self.text = lemmatize_token(self.text)\n",
    "        return self\n",
    "\n",
    "    def normalize(self):\n",
    "        self = self.convert2string()\n",
    "        self = self.lowercase()\n",
    "        self = self.remove_url()\n",
    "        self = self.replace_spec_chars()\n",
    "        self = self.remove_spec_chars()\n",
    "        self = self.get_tokens()\n",
    "        self = self.remove_stopwords()\n",
    "        self = self.lemmatize()\n",
    "        return self.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job Title Text Preprocessing: 100%|████████████████████████████████████████████| 18992/18992 [00:13<00:00, 1435.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chief financial officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full time community connection intern pay internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country coordinator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bcc specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>software developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18987</th>\n",
       "      <td>senior creative ux ui designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18988</th>\n",
       "      <td>category development manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18989</th>\n",
       "      <td>operational marketing manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18990</th>\n",
       "      <td>head online sale department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>lawyer legal department</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18992 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  job_title\n",
       "0                                   chief financial officer\n",
       "1      full time community connection intern pay internship\n",
       "2                                       country coordinator\n",
       "3                                            bcc specialist\n",
       "4                                        software developer\n",
       "...                                                     ...\n",
       "18987                        senior creative ux ui designer\n",
       "18988                          category development manager\n",
       "18989                         operational marketing manager\n",
       "18990                           head online sale department\n",
       "18991                               lawyer legal department\n",
       "\n",
       "[18992 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set stopwords, special characters, and rare_words to remove\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "spec_chars = string.punctuation + string.digits + \"\\n\\r\"\n",
    "\n",
    "# Normalize text\n",
    "tqdm.pandas(desc=\"Job Title Text Preprocessing\")\n",
    "clean_title_df = title_df.progress_applymap(\n",
    "    lambda x: pre_process_text(\n",
    "        x, spec_chars=spec_chars, stop_words=stop_words\n",
    "    ).normalize()\n",
    ")\n",
    "clean_title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_rare_words(text, rare_words):\n",
    "#     return \" \".join([word for word in text.split() if word not in rare_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove rare words\n",
    "# title_vocab = [\n",
    "#     item\n",
    "#     for sublist in clean_title_df[\"job_title\"].values.tolist()\n",
    "#     for item in nltk.word_tokenize(sublist)\n",
    "# ]\n",
    "# rare_words = [k for (k, v) in Counter(title_vocab).items() if v <= 1]\n",
    "\n",
    "# print(len(rare_words))\n",
    "# print(rare_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas(desc=\"Job Title Removing rare words\")\n",
    "# clean_title_df = clean_title_df.progress_applymap(\n",
    "#     lambda x: remove_rare_words(x, rare_words=rare_words)\n",
    "# )\n",
    "# clean_title_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save pre-processed text to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_title_df.to_csv(OUTPUT_DIR + \"clean_title_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
